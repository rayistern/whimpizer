# Whimperizer Configuration
api:
  # Default provider: openai, anthropic, google
  default_provider: "openai"
  
  # Fallback configuration - models to try if primary fails
  fallbacks:
    # First fallback model
    fallback_1:
      provider: "anthropic"
      model: "claude-3-sonnet-20240229"
      max_tokens: 4000
      temperature: 0.7
    
    # Second fallback model  
    fallback_2:
      provider: "openai"
      model: "gpt-4o-mini"
      temperature: 0.7
  
  # Provider-specific settings
  providers:
    openai:
      base_url: "https://api.openai.com/v1"
      model: "o4-mini"  # Reasoning model - fixed typo from o4-mini
      # max_tokens: 327680  # Commented out - not needed for most use cases
      temperature: 1
    
    anthropic:
      base_url: "https://api.anthropic.com"
      model: "claude-3-sonnet-20240229"
      max_tokens: 4000
      temperature: 0.7
    
    google:
      base_url: "https://generativelanguage.googleapis.com"
      model: "gemini-pro"
      max_tokens: 4000
      temperature: 0.7

processing:
  input_dir: "../output/downloaded_content"
  output_dir: "../output/whimperized_content"
  
# File naming patterns
patterns:
  input_file: "{group1}-{group2}-{line}.txt"
  output_file: "{group1}-{group2}-whimperized-{timestamp}.md"

# Processing options
options:
  combine_by_group: true  # Combine all files from same group1+group2 combination
  sort_by_line: true      # Process files in line number order within each group 